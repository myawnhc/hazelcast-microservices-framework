package com.theyawns.framework.pipeline;

import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.jet.Job;
import com.hazelcast.jet.config.JobConfig;
import com.hazelcast.jet.pipeline.JournalInitialPosition;
import com.hazelcast.jet.pipeline.Pipeline;
import com.hazelcast.jet.pipeline.ServiceFactories;
import com.hazelcast.jet.pipeline.ServiceFactory;
import com.hazelcast.jet.pipeline.Sinks;
import com.hazelcast.jet.pipeline.Sources;
import com.hazelcast.jet.pipeline.StreamStage;
import com.hazelcast.map.IMap;
import com.hazelcast.nio.serialization.genericrecord.GenericRecord;
import com.theyawns.framework.domain.DomainObject;
import com.theyawns.framework.event.DomainEvent;
import com.theyawns.framework.store.EventStore;
import com.theyawns.framework.store.EventStoreServiceCreator;
import com.theyawns.framework.store.HazelcastEventStore;
import com.theyawns.framework.store.PartitionedSequenceKey;
import com.theyawns.framework.view.HazelcastViewStore;
import com.theyawns.framework.view.ViewUpdater;
import com.theyawns.framework.view.ViewUpdaterServiceCreator;
import io.micrometer.core.instrument.MeterRegistry;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.Serializable;
import java.time.Instant;
import java.util.Map;
import java.util.Objects;

/**
 * Hazelcast Jet pipeline for event sourcing.
 * Processes events from the pending events map through 6 stages:
 *
 * <ol>
 *   <li><strong>Source</strong>: Read from pending events map via Event Journal</li>
 *   <li><strong>Enrich</strong>: Add pipeline entry timestamp and validate</li>
 *   <li><strong>Persist</strong>: Store event in the Event Store</li>
 *   <li><strong>Update View</strong>: Apply event to materialized view</li>
 *   <li><strong>Publish</strong>: Notify subscribers via event bus</li>
 *   <li><strong>Complete</strong>: Signal completion by updating completions map</li>
 * </ol>
 *
 * <p>The pipeline is designed to:
 * <ul>
 *   <li>Process events in order per domain object (partition-aware)</li>
 *   <li>Handle failures gracefully with logging</li>
 *   <li>Collect metrics at each stage</li>
 *   <li>Support both real-time and batch processing</li>
 * </ul>
 *
 * <p>Example usage:
 * <pre>{@code
 * EventSourcingPipeline<Customer, String, CustomerEvent> pipeline =
 *     EventSourcingPipeline.<Customer, String, CustomerEvent>builder()
 *         .hazelcast(hazelcastInstance)
 *         .domainName("Customer")
 *         .eventStore(customerEventStore)
 *         .viewUpdater(customerViewUpdater)
 *         .meterRegistry(meterRegistry)
 *         .build();
 *
 * Job job = pipeline.start();
 * }</pre>
 *
 * @param <D> The domain object type
 * @param <K> The domain object key type
 * @param <E> The event type
 * @author Generated by Claude Code
 * @since 1.0
 */
public class EventSourcingPipeline<D extends DomainObject<K>, K extends Comparable<K>,
        E extends DomainEvent<D, K>> implements Serializable {

    private static final long serialVersionUID = 1L;
    private static final Logger logger = LoggerFactory.getLogger(EventSourcingPipeline.class);

    private static final String PENDING_SUFFIX = "_PENDING";
    private static final String COMPLETIONS_SUFFIX = "_COMPLETIONS";

    private final HazelcastInstance hazelcast;
    private final String domainName;
    private final String pendingMapName;
    private final String completionsMapName;
    private final EventStore<D, K, E> eventStore;
    private final ViewUpdater<K> viewUpdater;
    private final Class<? extends ViewUpdater<K>> viewUpdaterClass;
    private final HazelcastEventBus<D, K> eventBus;
    private final PipelineMetrics metrics;
    private final MeterRegistry meterRegistry;

    private volatile Job pipelineJob;

    /**
     * Private constructor - use builder pattern.
     */
    private EventSourcingPipeline(Builder<D, K, E> builder) {
        this.hazelcast = builder.hazelcast;
        this.domainName = builder.domainName;
        this.pendingMapName = builder.domainName + PENDING_SUFFIX;
        this.completionsMapName = builder.domainName + COMPLETIONS_SUFFIX;
        this.eventStore = builder.eventStore;
        this.viewUpdater = builder.viewUpdater;
        this.viewUpdaterClass = builder.viewUpdaterClass;
        this.meterRegistry = builder.meterRegistry;

        // Create event bus if not provided
        if (builder.eventBus != null) {
            this.eventBus = builder.eventBus;
        } else {
            this.eventBus = new HazelcastEventBus<>(hazelcast, domainName);
        }

        // Create metrics collector
        this.metrics = new PipelineMetrics(meterRegistry, domainName);

        logger.info("EventSourcingPipeline created for domain: {}", domainName);
    }

    /**
     * Starts the Jet pipeline job.
     * The job will continuously process events from the pending map.
     *
     * @return the running Jet job
     */
    public Job start() {
        if (pipelineJob != null && !pipelineJob.isUserCancelled()) {
            logger.warn("Pipeline job already running for domain: {}", domainName);
            return pipelineJob;
        }

        Pipeline pipeline = buildPipeline();

        JobConfig jobConfig = new JobConfig()
                .setName(domainName + "-EventSourcingPipeline");

        pipelineJob = hazelcast.getJet().newJob(pipeline, jobConfig);
        logger.info("Started EventSourcingPipeline job for domain: {}, jobId: {}",
                domainName, pipelineJob.getId());

        return pipelineJob;
    }

    /**
     * Stops the pipeline job gracefully.
     */
    public void stop() {
        if (pipelineJob != null) {
            try {
                pipelineJob.cancel();
                logger.info("Stopped EventSourcingPipeline job for domain: {}", domainName);
            } catch (Exception e) {
                logger.error("Error stopping pipeline job for domain: {}", domainName, e);
            }
        }
    }

    /**
     * Returns whether the pipeline job is running.
     *
     * @return true if running
     */
    public boolean isRunning() {
        return pipelineJob != null && !pipelineJob.isUserCancelled();
    }

    /**
     * Returns the pipeline job.
     *
     * @return the job, or null if not started
     */
    public Job getJob() {
        return pipelineJob;
    }

    /**
     * Returns the domain name.
     *
     * @return the domain name
     */
    public String getDomainName() {
        return domainName;
    }

    /**
     * Returns the pending map name.
     *
     * @return the pending map name
     */
    public String getPendingMapName() {
        return pendingMapName;
    }

    /**
     * Returns the completions map name.
     *
     * @return the completions map name
     */
    public String getCompletionsMapName() {
        return completionsMapName;
    }

    /**
     * Returns the event bus.
     *
     * @return the event bus
     */
    public HazelcastEventBus<D, K> getEventBus() {
        return eventBus;
    }

    /**
     * Builds the Jet pipeline with all 6 stages.
     * IMPORTANT: All lambdas must avoid capturing 'this' or non-serializable fields.
     * We use local final variables to capture only the values needed.
     */
    private Pipeline buildPipeline() {
        Pipeline pipeline = Pipeline.create();

        // Capture required values in local final variables to avoid capturing 'this'
        final String localPendingMapName = this.pendingMapName;
        final String localCompletionsMapName = this.completionsMapName;
        final String localDomainName = this.domainName;
        final Class<? extends ViewUpdater<K>> localViewUpdaterClass = this.viewUpdaterClass;

        // Stage 1: SOURCE - Read from pending events map via Event Journal
        StreamStage<Map.Entry<PartitionedSequenceKey<K>, GenericRecord>> source = pipeline
                .readFrom(Sources.<PartitionedSequenceKey<K>, GenericRecord>mapJournal(
                        localPendingMapName,
                        JournalInitialPosition.START_FROM_OLDEST
                ))
                .withIngestionTimestamps()
                .setName("1-source-pending-events");

        // Stage 2: ENRICH - Add pipeline entry timestamp and validate
        // Note: Lambda must not capture non-serializable instance fields
        StreamStage<EventContext<K>> enriched = source
                .map(EventSourcingPipeline::enrichEvent)
                .setName("2-enrich-metadata");

        // Stage 3: PERSIST - Store event in Event Store
        // Using a service factory that creates the store from ProcessorContext
        // Using concrete class EventStoreServiceCreator to avoid lambda serialization issues
        EventStoreServiceCreator<D, K, E> eventStoreCreator = new EventStoreServiceCreator<>(localDomainName);
        ServiceFactory<?, HazelcastEventStore<D, K, E>> eventStoreFactory = ServiceFactories
                .<HazelcastEventStore<D, K, E>>sharedService(eventStoreCreator)
                .toNonCooperative();

        StreamStage<EventContext<K>> persisted = enriched
                .mapUsingService(eventStoreFactory, (store, ctx) -> {
                    try {
                        Instant start = Instant.now();
                        store.append(ctx.key, ctx.eventRecord);
                        return ctx.withPersisted(true, start);
                    } catch (Exception e) {
                        return ctx.withPersisted(false, Instant.now());
                    }
                })
                .setName("3-persist-event-store");

        // Stage 4: UPDATE VIEW - Apply event to materialized view using ViewUpdater
        // Create a ServiceFactory that produces a ViewUpdater with a fresh ViewStore
        // Using concrete class ViewUpdaterServiceCreator with class name to avoid lambda serialization issues
        ViewUpdaterServiceCreator<K> serviceCreator = new ViewUpdaterServiceCreator<>(
                localDomainName, localViewUpdaterClass);
        ServiceFactory<?, ViewUpdater<K>> viewUpdaterServiceFactory = ServiceFactories
                .<ViewUpdater<K>>sharedService(serviceCreator)
                .toNonCooperative();

        StreamStage<EventContext<K>> viewUpdated = persisted
                .mapUsingService(viewUpdaterServiceFactory, (viewUpdater, ctx) -> {
                    if (!ctx.persisted) {
                        return ctx; // Skip if persist failed
                    }
                    try {
                        Instant start = Instant.now();
                        // Apply event to view using the ViewUpdater's updateDirect method
                        // This properly transforms the event into domain state
                        viewUpdater.updateDirect(ctx.eventRecord);
                        return ctx.withViewUpdated(true, start);
                    } catch (Exception e) {
                        logger.warn("Failed to update view for event: {}", ctx.eventId, e);
                        return ctx.withViewUpdated(false, Instant.now());
                    }
                })
                .setName("4-update-materialized-view");

        // Stage 5: PUBLISH - Mark as published (actual event bus not used in pipeline)
        StreamStage<EventContext<K>> published = viewUpdated
                .map(ctx -> {
                    if (!ctx.viewUpdated) {
                        return ctx;
                    }
                    return ctx.withPublished(true, Instant.now());
                })
                .setName("5-publish-to-subscribers");

        // Stage 6: COMPLETE - Signal completion by updating completions map
        // Use map() to transform to entry, then write to map sink
        // This avoids serialization issues with EventContext
        published.map(ctx -> Map.entry(ctx.key, ctx.eventRecord))
                .writeTo(Sinks.map(localCompletionsMapName))
                .setName("6-signal-completion");

        return pipeline;
    }

    /**
     * Static method for Stage 2 enrichment - can be used as method reference.
     * Must be static to avoid capturing non-serializable instance fields.
     */
    @SuppressWarnings("unchecked")
    private static <K> EventContext<K> enrichEvent(Map.Entry<PartitionedSequenceKey<K>, GenericRecord> entry) {
        Instant pipelineEntryTime = Instant.now();
        PartitionedSequenceKey<K> key = entry.getKey();
        GenericRecord eventRecord = entry.getValue();

        String eventType = extractEventType(eventRecord);
        String eventId = extractEventId(eventRecord);

        return new EventContext<>(key, eventRecord, eventType, eventId, pipelineEntryTime);
    }

    /**
     * Helper to extract event type from GenericRecord.
     * Static to avoid capturing non-serializable references in lambdas.
     */
    private static String extractEventType(GenericRecord record) {
        try {
            return record.getString("eventType");
        } catch (Exception e) {
            return "unknown";
        }
    }

    /**
     * Helper to extract event ID from GenericRecord.
     * Static to avoid capturing non-serializable references in lambdas.
     */
    private static String extractEventId(GenericRecord record) {
        try {
            return record.getString("eventId");
        } catch (Exception e) {
            return "unknown";
        }
    }

    // ==================== Builder Pattern ====================

    /**
     * Creates a new builder for EventSourcingPipeline.
     *
     * @param <D> The domain object type
     * @param <K> The domain object key type
     * @param <E> The event type
     * @return a new builder
     */
    public static <D extends DomainObject<K>, K extends Comparable<K>,
            E extends DomainEvent<D, K>> Builder<D, K, E> builder() {
        return new Builder<>();
    }

    /**
     * Builder for EventSourcingPipeline.
     *
     * @param <D> The domain object type
     * @param <K> The domain object key type
     * @param <E> The event type
     */
    public static class Builder<D extends DomainObject<K>, K extends Comparable<K>,
            E extends DomainEvent<D, K>> {

        private HazelcastInstance hazelcast;
        private String domainName;
        private EventStore<D, K, E> eventStore;
        private ViewUpdater<K> viewUpdater;
        private Class<? extends ViewUpdater<K>> viewUpdaterClass;
        private HazelcastEventBus<D, K> eventBus;
        private MeterRegistry meterRegistry;

        /**
         * Sets the Hazelcast instance.
         *
         * @param hazelcast the Hazelcast instance
         * @return this builder
         */
        public Builder<D, K, E> hazelcast(HazelcastInstance hazelcast) {
            this.hazelcast = hazelcast;
            return this;
        }

        /**
         * Sets the domain name.
         *
         * @param domainName the domain name
         * @return this builder
         */
        public Builder<D, K, E> domainName(String domainName) {
            this.domainName = domainName;
            return this;
        }

        /**
         * Sets the event store.
         *
         * @param eventStore the event store
         * @return this builder
         */
        public Builder<D, K, E> eventStore(EventStore<D, K, E> eventStore) {
            this.eventStore = eventStore;
            return this;
        }

        /**
         * Sets the view updater.
         *
         * @param viewUpdater the view updater
         * @return this builder
         */
        public Builder<D, K, E> viewUpdater(ViewUpdater<K> viewUpdater) {
            this.viewUpdater = viewUpdater;
            return this;
        }

        /**
         * Sets the view updater class for creating ViewUpdaters within the distributed pipeline.
         * This is required because ViewUpdater's transient viewStore field is lost during
         * serialization, so we need a class reference to recreate it with a fresh ViewStore
         * using reflection.
         *
         * @param viewUpdaterClass the ViewUpdater class to instantiate
         * @return this builder
         */
        public Builder<D, K, E> viewUpdaterClass(Class<? extends ViewUpdater<K>> viewUpdaterClass) {
            this.viewUpdaterClass = viewUpdaterClass;
            return this;
        }

        /**
         * Sets the event bus (optional - will be created if not provided).
         *
         * @param eventBus the event bus
         * @return this builder
         */
        public Builder<D, K, E> eventBus(HazelcastEventBus<D, K> eventBus) {
            this.eventBus = eventBus;
            return this;
        }

        /**
         * Sets the meter registry for metrics.
         *
         * @param meterRegistry the meter registry
         * @return this builder
         */
        public Builder<D, K, E> meterRegistry(MeterRegistry meterRegistry) {
            this.meterRegistry = meterRegistry;
            return this;
        }

        /**
         * Builds the EventSourcingPipeline.
         *
         * @return the configured pipeline
         * @throws NullPointerException if required parameters are missing
         */
        public EventSourcingPipeline<D, K, E> build() {
            Objects.requireNonNull(hazelcast, "hazelcast is required");
            Objects.requireNonNull(domainName, "domainName is required");
            Objects.requireNonNull(eventStore, "eventStore is required");
            Objects.requireNonNull(viewUpdater, "viewUpdater is required");
            Objects.requireNonNull(viewUpdaterClass, "viewUpdaterClass is required");
            Objects.requireNonNull(meterRegistry, "meterRegistry is required");

            return new EventSourcingPipeline<>(this);
        }
    }

    // ==================== Event Context (internal) ====================

    /**
     * Internal context object that flows through the pipeline stages.
     * Carries the event data plus processing metadata.
     */
    private static class EventContext<K> implements Serializable {

        private static final long serialVersionUID = 1L;

        final PartitionedSequenceKey<K> key;
        final GenericRecord eventRecord;
        final String eventType;
        final String eventId;
        final Instant pipelineEntryTime;

        // Stage completion flags
        boolean persisted;
        boolean viewUpdated;
        boolean published;

        // Stage timing
        Instant persistTime;
        Instant viewUpdateTime;
        Instant publishTime;

        EventContext(PartitionedSequenceKey<K> key, GenericRecord eventRecord,
                     String eventType, String eventId, Instant pipelineEntryTime) {
            this.key = key;
            this.eventRecord = eventRecord;
            this.eventType = eventType;
            this.eventId = eventId;
            this.pipelineEntryTime = pipelineEntryTime;
        }

        EventContext<K> withPersisted(boolean persisted, Instant time) {
            this.persisted = persisted;
            this.persistTime = time;
            return this;
        }

        EventContext<K> withViewUpdated(boolean viewUpdated, Instant time) {
            this.viewUpdated = viewUpdated;
            this.viewUpdateTime = time;
            return this;
        }

        EventContext<K> withPublished(boolean published, Instant time) {
            this.published = published;
            this.publishTime = time;
            return this;
        }
    }
}
