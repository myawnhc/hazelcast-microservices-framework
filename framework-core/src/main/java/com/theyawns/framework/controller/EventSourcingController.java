package com.theyawns.framework.controller;

import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.flakeidgen.FlakeIdGenerator;
import com.hazelcast.jet.Job;
import com.hazelcast.map.IMap;
import com.hazelcast.nio.serialization.genericrecord.GenericRecord;
import com.hazelcast.topic.ITopic;
import com.theyawns.framework.domain.DomainObject;
import com.theyawns.framework.event.DomainEvent;
import com.theyawns.framework.outbox.OutboxEntry;
import com.theyawns.framework.outbox.OutboxStore;
import com.theyawns.framework.pipeline.EventSourcingPipeline;
import com.theyawns.framework.pipeline.HazelcastEventBus;
import com.theyawns.framework.pipeline.PipelineMetrics;
import com.theyawns.framework.security.identity.EventAuthenticator;
import com.theyawns.framework.store.EventStore;
import com.theyawns.framework.store.PartitionedSequenceKey;
import com.theyawns.framework.tracing.EventSpanDecorator;
import com.theyawns.framework.view.HazelcastViewStore;
import com.theyawns.framework.view.ViewUpdater;
import io.micrometer.core.instrument.MeterRegistry;
import io.micrometer.tracing.Span;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.time.Duration;
import java.time.Instant;
import java.util.Objects;
import java.util.Optional;
import java.util.UUID;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;

/**
 * Main controller for the event sourcing framework.
 * Provides the central handleEvent() method that all services use to process events.
 *
 * <p>Responsibilities:
 * <ul>
 *   <li>Accept events via handleEvent()</li>
 *   <li>Assign sequence numbers using FlakeIdGenerator</li>
 *   <li>Write to PendingEvents (triggers pipeline)</li>
 *   <li>Track completion via CompletionInfo</li>
 *   <li>Return CompletableFuture for async responses</li>
 * </ul>
 *
 * <p>Example usage:
 * <pre>{@code
 * EventSourcingController<Customer, String, CustomerEvent> controller =
 *     EventSourcingController.<Customer, String, CustomerEvent>builder()
 *         .hazelcast(hazelcastInstance)
 *         .domainName("Customer")
 *         .eventStore(customerEventStore)
 *         .viewUpdater(customerViewUpdater)
 *         .meterRegistry(meterRegistry)
 *         .build();
 *
 * // Start the pipeline
 * controller.start();
 *
 * // Handle an event
 * CompletableFuture<CompletionInfo<String>> future =
 *     controller.handleEvent(customerCreatedEvent);
 *
 * // Get completion info
 * CompletionInfo<String> info = future.get();
 * }</pre>
 *
 * @param <D> Domain object type
 * @param <K> Domain object key type (must be Comparable)
 * @param <E> Base event type for this domain
 * @author Generated by Claude Code
 * @since 1.0
 */
public class EventSourcingController<D extends DomainObject<K>,
        K extends Comparable<K>,
        E extends DomainEvent<D, K>> {

    private static final Logger logger = LoggerFactory.getLogger(EventSourcingController.class);

    private static final String PENDING_SUFFIX = "_PENDING";
    private static final String VIEW_SUFFIX = "_VIEW";
    private static final String SEQUENCE_GEN_SUFFIX = "_SEQ";

    private final HazelcastInstance hazelcast;
    private final HazelcastInstance sharedHazelcast;
    private final String domainName;
    private final FlakeIdGenerator sequenceGenerator;
    private final EventStore<D, K, E> eventStore;
    private final ViewUpdater<K> viewUpdater;
    private final Class<? extends ViewUpdater<K>> viewUpdaterClass;
    private final IMap<PartitionedSequenceKey<K>, GenericRecord> pendingEventsMap;
    private final MeterRegistry meterRegistry;
    private final PipelineMetrics pipelineMetrics;
    private final EventSpanDecorator eventSpanDecorator;
    private final OutboxStore outboxStore;
    private final EventAuthenticator eventAuthenticator;
    private final EventSourcingPipeline<D, K, E> pipeline;

    /**
     * Tracks pending completions for async notification.
     * Maps the event's eventId (String) to both the future and the pre-built CompletionInfo.
     * Using eventId (a simple String) instead of PartitionedSequenceKey avoids
     * serialization round-trip issues with custom key types in Hazelcast listeners.
     */
    private final ConcurrentMap<String, PendingCompletion<K>> pendingCompletions;

    /** Counter for pipeline completions received without a matching pending entry. */
    private final AtomicLong orphanedCompletions = new AtomicLong(0);

    /** Timer for ITopic publish duration to shared cluster. */
    private final io.micrometer.core.instrument.Timer topicPublishTimer;

    /**
     * Private constructor - use builder.
     */
    private EventSourcingController(Builder<D, K, E> builder) {
        this.hazelcast = builder.hazelcast;
        this.sharedHazelcast = builder.sharedHazelcast;
        this.domainName = builder.domainName;
        this.eventStore = builder.eventStore;
        this.viewUpdater = builder.viewUpdater;
        this.viewUpdaterClass = builder.viewUpdaterClass;
        this.meterRegistry = builder.meterRegistry;
        this.pipelineMetrics = new PipelineMetrics(meterRegistry, domainName);
        this.eventSpanDecorator = builder.eventSpanDecorator;
        this.outboxStore = builder.outboxStore;
        this.eventAuthenticator = builder.eventAuthenticator;

        // Initialize Hazelcast structures
        this.sequenceGenerator = hazelcast.getFlakeIdGenerator(domainName + SEQUENCE_GEN_SUFFIX);
        this.pendingEventsMap = hazelcast.getMap(domainName + PENDING_SUFFIX);
        this.pendingCompletions = new ConcurrentHashMap<>();

        // Performance gauges for monitoring pending work
        meterRegistry.gauge("eventsourcing.pending.completions",
                java.util.Collections.singletonList(io.micrometer.core.instrument.Tag.of("domain", domainName)),
                pendingCompletions, ConcurrentMap::size);
        meterRegistry.gauge("eventsourcing.pending.events",
                java.util.Collections.singletonList(io.micrometer.core.instrument.Tag.of("domain", domainName)),
                pendingEventsMap, IMap::size);
        meterRegistry.gauge("eventsourcing.completions.orphaned",
                java.util.Collections.singletonList(io.micrometer.core.instrument.Tag.of("domain", domainName)),
                orphanedCompletions);

        this.topicPublishTimer = io.micrometer.core.instrument.Timer.builder("eventsourcing.itopic.publish.duration")
                .tag("domain", domainName)
                .publishPercentiles(0.5, 0.95, 0.99)
                .register(meterRegistry);

        // Listen for pipeline completions on the completions map.
        // The pipeline writes a PipelineCompletion GenericRecord with timing metadata.
        // We extract timing here (where MeterRegistry is available) to record metrics.
        IMap<String, GenericRecord> completionsMap =
                hazelcast.getMap(domainName + "_COMPLETIONS");
        completionsMap.addEntryListener(
                (com.hazelcast.map.listener.EntryAddedListener<String, GenericRecord>)
                        event -> {
                            String eventId = event.getKey();
                            GenericRecord completion = event.getValue();
                            PendingCompletion<K> pending = pendingCompletions.remove(eventId);
                            if (pending != null) {
                                pending.completionInfo.markCompleted();
                                pending.future.complete(pending.completionInfo);
                                logger.debug("Pipeline completed for event: {} (eventId: {})",
                                        pending.completionInfo.getEventType(), eventId);

                                // Republish the event to the shared cluster's ITopic
                                // so saga listeners on other services can receive it
                                republishToSharedCluster(pending);
                            } else {
                                orphanedCompletions.incrementAndGet();
                                logger.warn("Orphaned pipeline completion for eventId: {}", eventId);
                            }
                            recordPipelineMetrics(completion, pending);
                        },
                true);

        // Build the pipeline
        EventSourcingPipeline.Builder<D, K, E> pipelineBuilder =
                EventSourcingPipeline.<D, K, E>builder()
                        .hazelcast(hazelcast)
                        .domainName(domainName)
                        .eventStore(eventStore)
                        .viewUpdater(viewUpdater)
                        .viewUpdaterClass(viewUpdaterClass)
                        .meterRegistry(meterRegistry);

        if (builder.eventBus != null) {
            pipelineBuilder.eventBus(builder.eventBus);
        }

        this.pipeline = pipelineBuilder.build();

        logger.info("EventSourcingController initialized for domain: {}", domainName);
    }

    /**
     * Starts the event sourcing pipeline.
     * Must be called before handling events.
     *
     * @return the running Jet job
     */
    public Job start() {
        Job job = pipeline.start();
        logger.info("EventSourcingController started for domain: {}", domainName);
        return job;
    }

    /**
     * Stops the event sourcing pipeline.
     */
    public void stop() {
        pipeline.stop();
        logger.info("EventSourcingController stopped for domain: {}", domainName);
    }

    /**
     * Returns whether the pipeline is running.
     *
     * @return true if running
     */
    public boolean isRunning() {
        return pipeline.isRunning();
    }

    /**
     * Central event handling method with full parameters.
     *
     * <p>Process:
     * <ol>
     *   <li>Set event metadata (correlation ID, timestamp, source)</li>
     *   <li>Assign sequence number via FlakeIdGenerator</li>
     *   <li>Write to PendingEvents map (triggers pipeline)</li>
     *   <li>Return future that completes when processing finishes</li>
     * </ol>
     *
     * @param event the domain event to process
     * @param correlationId UUID linking related events across services
     * @param sagaMetadata optional saga information (null if not part of saga)
     * @return CompletableFuture that completes when event is processed
     */
    public CompletableFuture<CompletionInfo<K>> handleEvent(
            E event,
            UUID correlationId,
            SagaMetadata sagaMetadata) {

        Objects.requireNonNull(event, "event cannot be null");
        Objects.requireNonNull(correlationId, "correlationId cannot be null");

        // Start tracing span if decorator is available
        Span span = null;
        if (eventSpanDecorator != null) {
            // Set metadata first so span captures it
            event.setCorrelationId(correlationId.toString());
            event.setSource(domainName);
            span = eventSpanDecorator.startEventSpan(event);
        }

        try {
            // Set metadata (idempotent if already set above)
            event.setCorrelationId(correlationId.toString());
            event.setSource(domainName);
            event.setSubmittedAt(Instant.now());

            // Saga support
            if (sagaMetadata != null) {
                event.setSagaId(sagaMetadata.getSagaId());
                event.setSagaType(sagaMetadata.getSagaType());
                event.setStepNumber(sagaMetadata.getStepNumber());
                event.setIsCompensating(sagaMetadata.getIsCompensating());
            }

            // Assign sequence number
            long sequence = sequenceGenerator.newId();
            PartitionedSequenceKey<K> psk = new PartitionedSequenceKey<>(sequence, event.getKey());

            // Create completion tracker
            CompletionInfo<K> completionInfo = new CompletionInfo<>(
                    psk, correlationId, event.getEventType(), event.getEventId());

            CompletableFuture<CompletionInfo<K>> future = new CompletableFuture<>();

            // Write to pending events map (TRIGGERS PIPELINE)
            GenericRecord eventRecord = event.toGenericRecord();

            // Store event record + type for cross-cluster republishing on completion
            pendingCompletions.put(event.getEventId(),
                    new PendingCompletion<>(future, completionInfo, eventRecord, event.getEventType()));
            pendingEventsMap.set(psk, eventRecord);

            // Record metrics
            meterRegistry.counter("eventsourcing.events.submitted",
                    "eventType", event.getEventType(),
                    "domain", domainName
            ).increment();

            logger.debug("Event submitted: {} (key: {}, correlation: {}, sequence: {})",
                    event.getEventType(), event.getKey(), correlationId, sequence);

            // End tracing span on success (covers submission; pipeline stages have own spans)
            if (eventSpanDecorator != null) {
                eventSpanDecorator.endSpan(span);
            }

            // Future completes when the pipeline writes to the completions map
            // (via the EntryAddedListener registered in constructor).
            // Add a safety timeout to avoid hanging indefinitely if the pipeline fails.
            final String eventId = event.getEventId();
            return future.orTimeout(30, TimeUnit.SECONDS)
                    .whenComplete((result, throwable) -> {
                        if (throwable != null) {
                            // Clean up the pending entry on failure/timeout
                            pendingCompletions.remove(eventId);
                            if (throwable instanceof java.util.concurrent.TimeoutException) {
                                logger.error("Pipeline timeout after 30s for event: {} (type: {}, key: {}, seq: {}). "
                                                + "Pipeline running: {}, pending completions: {}",
                                        eventId, event.getEventType(), event.getKey(),
                                        sequence, pipeline.isRunning(), pendingCompletions.size());
                            }
                        }
                    });

        } catch (Exception e) {
            logger.error("Failed to handle event: {} for key: {}",
                    event.getEventType(), event.getKey(), e);

            // Record error in tracing span
            if (eventSpanDecorator != null) {
                eventSpanDecorator.recordError(span, e);
                eventSpanDecorator.endSpan(span);
            }

            meterRegistry.counter("eventsourcing.events.failed",
                    "eventType", event.getEventType(),
                    "domain", domainName
            ).increment();

            CompletableFuture<CompletionInfo<K>> failedFuture = new CompletableFuture<>();
            failedFuture.completeExceptionally(e);
            return failedFuture;
        }
    }

    /**
     * Handles an event with correlation ID but no saga metadata.
     *
     * @param event the domain event to process
     * @param correlationId UUID linking related events
     * @return CompletableFuture that completes when event is processed
     */
    public CompletableFuture<CompletionInfo<K>> handleEvent(E event, UUID correlationId) {
        return handleEvent(event, correlationId, null);
    }

    /**
     * Handles an event with auto-generated correlation ID.
     *
     * @param event the domain event to process
     * @return CompletableFuture that completes when event is processed
     */
    public CompletableFuture<CompletionInfo<K>> handleEvent(E event) {
        return handleEvent(event, UUID.randomUUID(), null);
    }

    /**
     * Retrieves the current state of a domain object from the materialized view.
     *
     * @param key the domain object key
     * @return the current state, or empty if not found
     */
    public Optional<GenericRecord> getViewState(K key) {
        return viewUpdater.getViewStore().get(key);
    }

    /**
     * Rebuilds the entire view from the event store.
     * Use with caution - this can be expensive for large event stores.
     *
     * @return the number of events replayed
     */
    public long rebuildView() {
        logger.info("Rebuilding view for domain: {}", domainName);
        return viewUpdater.rebuild(eventStore);
    }

    /**
     * Rebuilds the view for a single domain object.
     *
     * @param key the domain object key
     * @return the final view state, or empty if no events
     */
    public Optional<GenericRecord> rebuildViewForKey(K key) {
        logger.info("Rebuilding view for key: {} in domain: {}", key, domainName);
        return viewUpdater.rebuildForKey(key, eventStore);
    }

    // Getters

    /**
     * Returns the domain name.
     *
     * @return the domain name
     */
    public String getDomainName() {
        return domainName;
    }

    /**
     * Returns the event store.
     *
     * @return the event store
     */
    public EventStore<D, K, E> getEventStore() {
        return eventStore;
    }

    /**
     * Returns the view store.
     *
     * @return the view store
     */
    public HazelcastViewStore<K> getViewStore() {
        return viewUpdater.getViewStore();
    }

    /**
     * Returns the event bus.
     *
     * @return the event bus
     */
    public HazelcastEventBus<D, K> getEventBus() {
        return pipeline.getEventBus();
    }

    /**
     * Returns the Hazelcast instance.
     *
     * @return the Hazelcast instance
     */
    public HazelcastInstance getHazelcast() {
        return hazelcast;
    }

    /**
     * Returns the pipeline.
     *
     * @return the event sourcing pipeline
     */
    public EventSourcingPipeline<D, K, E> getPipeline() {
        return pipeline;
    }

    /**
     * Returns the shared Hazelcast instance (client connected to external cluster),
     * or null if not configured.
     *
     * @return the shared Hazelcast instance, or null
     */
    public HazelcastInstance getSharedHazelcast() {
        return sharedHazelcast;
    }

    // ==================== Cross-Cluster Publishing ====================

    /**
     * Republishes a completed event to the shared cluster's ITopic so that
     * saga listeners on other services can receive it. This bridges the gap
     * between the local embedded Hazelcast instance (used for Jet pipeline
     * processing) and the external shared cluster (used for cross-service
     * communication).
     *
     * <p>Only publishes if a shared Hazelcast instance is configured and the
     * event record is available.
     *
     * @param pending the completed event's pending completion data
     */
    private void republishToSharedCluster(PendingCompletion<K> pending) {
        if (sharedHazelcast == null || pending.eventRecord == null || pending.eventType == null) {
            return;
        }

        // Wrap event in authenticated envelope if service identity is configured
        final GenericRecord recordToPublish = (eventAuthenticator != null)
                ? eventAuthenticator.wrapWithAuthentication(pending.eventRecord, pending.eventType)
                : pending.eventRecord;

        if (outboxStore != null) {
            // Durable outbox path â€” OutboxPublisher handles actual delivery
            OutboxEntry entry = new OutboxEntry(
                    pending.completionInfo.getEventId(),
                    pending.eventType,
                    recordToPublish
            );
            outboxStore.write(entry);
            logger.debug("Wrote event {} to outbox for deferred shared cluster delivery",
                    pending.eventType);
        } else {
            // Legacy direct publish (when outbox is disabled)
            try {
                ITopic<GenericRecord> topic = sharedHazelcast.getTopic(pending.eventType);
                topicPublishTimer.record(() -> topic.publish(recordToPublish));
                logger.debug("Republished event {} to shared cluster topic: {}", pending.eventType, pending.eventType);
            } catch (Exception e) {
                logger.warn("Failed to republish event {} to shared cluster: {}", pending.eventType, e.getMessage());
            }
        }
    }

    // ==================== Pipeline Metrics ====================

    /**
     * Extracts timing fields from the PipelineCompletion record and records
     * all pipeline metrics. Called from the completions map EntryAddedListener.
     *
     * @param completion the PipelineCompletion GenericRecord from Stage 6
     * @param pending the pending completion info (may be null for orphan completions)
     */
    private void recordPipelineMetrics(GenericRecord completion, PendingCompletion<K> pending) {
        try {
            final String eventType = completion.getString("eventType");
            final boolean persisted = completion.getBoolean("persisted");
            final boolean viewUpdated = completion.getBoolean("viewUpdated");
            final boolean published = completion.getBoolean("published");
            final long pipelineEntryMs = completion.getInt64("pipelineEntryMs");
            final long persistStartMs = completion.getInt64("persistStartMs");
            final long viewUpdateStartMs = completion.getInt64("viewUpdateStartMs");
            final long publishTimeMs = completion.getInt64("publishTimeMs");
            final long completionMs = completion.getInt64("completionMs");

            // Always record received
            pipelineMetrics.recordEventReceived(eventType);

            // Record processed or failed
            if (persisted && viewUpdated && published) {
                pipelineMetrics.recordEventProcessed(eventType);
            } else if (!persisted) {
                pipelineMetrics.recordEventFailed(eventType, PipelineMetrics.PipelineStage.PERSIST);
            } else if (!viewUpdated) {
                pipelineMetrics.recordEventFailed(eventType, PipelineMetrics.PipelineStage.UPDATE_VIEW);
            } else {
                pipelineMetrics.recordEventFailed(eventType, PipelineMetrics.PipelineStage.PUBLISH);
            }

            // Stage timings (derived from sequential stage boundaries)
            if (persistStartMs > 0 && viewUpdateStartMs > 0) {
                pipelineMetrics.recordStageTiming(PipelineMetrics.PipelineStage.PERSIST, eventType,
                        Duration.ofMillis(viewUpdateStartMs - persistStartMs));
            }
            if (viewUpdateStartMs > 0 && publishTimeMs > 0) {
                pipelineMetrics.recordStageTiming(PipelineMetrics.PipelineStage.UPDATE_VIEW, eventType,
                        Duration.ofMillis(publishTimeMs - viewUpdateStartMs));
            }
            if (publishTimeMs > 0 && completionMs > 0) {
                pipelineMetrics.recordStageTiming(PipelineMetrics.PipelineStage.PUBLISH, eventType,
                        Duration.ofMillis(completionMs - publishTimeMs));
            }

            // View and publish counters
            if (viewUpdated) {
                pipelineMetrics.recordViewUpdated(eventType);
            }
            if (published) {
                pipelineMetrics.recordEventPublished(eventType);
            }

            // End-to-end and queue wait (require submittedAt from CompletionInfo)
            if (pending != null && pending.completionInfo.getSubmittedAt() != null) {
                long submittedMs = pending.completionInfo.getSubmittedAt().toEpochMilli();
                pipelineMetrics.recordEndToEndLatency(eventType,
                        Duration.ofMillis(completionMs - submittedMs));
                pipelineMetrics.recordQueueWaitTime(eventType,
                        Duration.ofMillis(pipelineEntryMs - submittedMs));
            }
        } catch (Exception e) {
            logger.warn("Failed to record pipeline metrics for completion record", e);
        }
    }

    // Builder

    /**
     * Creates a new builder for EventSourcingController.
     *
     * @param <D> Domain object type
     * @param <K> Domain object key type
     * @param <E> Event type
     * @return a new builder
     */
    public static <D extends DomainObject<K>, K extends Comparable<K>,
            E extends DomainEvent<D, K>> Builder<D, K, E> builder() {
        return new Builder<>();
    }

    /**
     * Builder for EventSourcingController.
     *
     * @param <D> Domain object type
     * @param <K> Domain object key type
     * @param <E> Event type
     */
    public static class Builder<D extends DomainObject<K>, K extends Comparable<K>,
            E extends DomainEvent<D, K>> {

        private HazelcastInstance hazelcast;
        private HazelcastInstance sharedHazelcast;
        private String domainName;
        private EventStore<D, K, E> eventStore;
        private ViewUpdater<K> viewUpdater;
        private Class<? extends ViewUpdater<K>> viewUpdaterClass;
        private HazelcastEventBus<D, K> eventBus;
        private MeterRegistry meterRegistry;
        private EventSpanDecorator eventSpanDecorator;
        private OutboxStore outboxStore;
        private EventAuthenticator eventAuthenticator;

        /**
         * Sets the Hazelcast instance.
         *
         * @param hazelcast the Hazelcast instance
         * @return this builder
         */
        public Builder<D, K, E> hazelcast(HazelcastInstance hazelcast) {
            this.hazelcast = hazelcast;
            return this;
        }

        /**
         * Sets the shared Hazelcast instance for cross-service communication (optional).
         *
         * <p>When set, the controller republishes events to the shared cluster's ITopic
         * after local pipeline processing completes. This enables saga listeners on
         * other services to receive events without requiring the local Hazelcast
         * instance to join the shared cluster (which would cause Jet lambda
         * serialization failures).
         *
         * @param sharedHazelcast the shared Hazelcast client instance
         * @return this builder
         */
        public Builder<D, K, E> sharedHazelcast(HazelcastInstance sharedHazelcast) {
            this.sharedHazelcast = sharedHazelcast;
            return this;
        }

        /**
         * Sets the domain name.
         *
         * @param domainName the domain name (e.g., "Customer", "Order")
         * @return this builder
         */
        public Builder<D, K, E> domainName(String domainName) {
            this.domainName = domainName;
            return this;
        }

        /**
         * Sets the event store.
         *
         * @param eventStore the event store
         * @return this builder
         */
        public Builder<D, K, E> eventStore(EventStore<D, K, E> eventStore) {
            this.eventStore = eventStore;
            return this;
        }

        /**
         * Sets the view updater.
         *
         * @param viewUpdater the view updater
         * @return this builder
         */
        public Builder<D, K, E> viewUpdater(ViewUpdater<K> viewUpdater) {
            this.viewUpdater = viewUpdater;
            return this;
        }

        /**
         * Sets the view updater class for creating ViewUpdaters within the distributed pipeline.
         * This class is used via reflection to create ViewUpdater instances on each cluster node.
         *
         * @param viewUpdaterClass the ViewUpdater class to instantiate
         * @return this builder
         */
        public Builder<D, K, E> viewUpdaterClass(Class<? extends ViewUpdater<K>> viewUpdaterClass) {
            this.viewUpdaterClass = viewUpdaterClass;
            return this;
        }

        /**
         * Sets the event bus (optional - will be created if not provided).
         *
         * @param eventBus the event bus
         * @return this builder
         */
        public Builder<D, K, E> eventBus(HazelcastEventBus<D, K> eventBus) {
            this.eventBus = eventBus;
            return this;
        }

        /**
         * Sets the meter registry for metrics.
         *
         * @param meterRegistry the meter registry
         * @return this builder
         */
        public Builder<D, K, E> meterRegistry(MeterRegistry meterRegistry) {
            this.meterRegistry = meterRegistry;
            return this;
        }

        /**
         * Sets the event span decorator for distributed tracing (optional).
         *
         * @param eventSpanDecorator the span decorator
         * @return this builder
         */
        public Builder<D, K, E> eventSpanDecorator(EventSpanDecorator eventSpanDecorator) {
            this.eventSpanDecorator = eventSpanDecorator;
            return this;
        }

        /**
         * Sets the outbox store for durable cross-cluster event delivery (optional).
         *
         * <p>When set, the controller writes events to the outbox instead of
         * publishing directly to the shared cluster's ITopic. The
         * {@link OutboxStore} handles actual delivery with retry logic.
         *
         * <p>When not set, the controller falls back to direct ITopic publishing.
         *
         * @param outboxStore the outbox store
         * @return this builder
         */
        public Builder<D, K, E> outboxStore(OutboxStore outboxStore) {
            this.outboxStore = outboxStore;
            return this;
        }

        /**
         * Sets the event authenticator for signing events published to the shared cluster (optional).
         *
         * <p>When set, events are wrapped in an authenticated envelope containing
         * the service identity and HMAC signature before being published to ITopic.
         * Saga listeners on receiving services unwrap and verify the signature.
         *
         * <p>When not set, events are published without authentication (backward compatible).
         *
         * @param eventAuthenticator the event authenticator
         * @return this builder
         */
        public Builder<D, K, E> eventAuthenticator(EventAuthenticator eventAuthenticator) {
            this.eventAuthenticator = eventAuthenticator;
            return this;
        }

        /**
         * Builds the EventSourcingController.
         *
         * @return the configured controller
         * @throws NullPointerException if required parameters are missing
         */
        public EventSourcingController<D, K, E> build() {
            Objects.requireNonNull(hazelcast, "hazelcast is required");
            Objects.requireNonNull(domainName, "domainName is required");
            Objects.requireNonNull(eventStore, "eventStore is required");
            Objects.requireNonNull(viewUpdater, "viewUpdater is required");
            Objects.requireNonNull(viewUpdaterClass, "viewUpdaterClass is required");
            Objects.requireNonNull(meterRegistry, "meterRegistry is required");

            return new EventSourcingController<>(this);
        }
    }

    // ==================== Internal Helper ====================

    /**
     * Pairs a CompletableFuture with its pre-built CompletionInfo for async resolution
     * when the pipeline signals completion via the completions map.
     */
    private static class PendingCompletion<K extends Comparable<K>> {

        final CompletableFuture<CompletionInfo<K>> future;
        final CompletionInfo<K> completionInfo;
        final GenericRecord eventRecord;
        final String eventType;

        PendingCompletion(CompletableFuture<CompletionInfo<K>> future, CompletionInfo<K> completionInfo,
                          GenericRecord eventRecord, String eventType) {
            this.future = future;
            this.completionInfo = completionInfo;
            this.eventRecord = eventRecord;
            this.eventType = eventType;
        }
    }
}
