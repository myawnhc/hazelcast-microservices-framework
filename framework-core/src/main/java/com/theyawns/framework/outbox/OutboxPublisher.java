package com.theyawns.framework.outbox;

import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.nio.serialization.genericrecord.GenericRecord;
import com.hazelcast.topic.ITopic;
import io.micrometer.core.instrument.MeterRegistry;
import io.micrometer.core.instrument.Timer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.List;
import java.util.Objects;
import java.util.UUID;
import java.util.concurrent.Semaphore;

/**
 * Polls the {@link OutboxStore} for pending entries and delivers them
 * to the shared cluster's ITopic.
 *
 * <p>Runs on a configurable schedule (default: every 1 second). Each cycle:
 * <ol>
 *   <li>Polls for up to {@code maxBatchSize} pending entries</li>
 *   <li>Publishes each entry to its target ITopic on the shared cluster</li>
 *   <li>Marks entries as DELIVERED on success</li>
 *   <li>Increments retry count on failure</li>
 *   <li>Marks entries as FAILED when max retries are exceeded</li>
 * </ol>
 *
 * <p>When no shared Hazelcast instance is configured, the publisher logs
 * a warning once and skips delivery (graceful degradation).
 *
 * @author Generated by Claude Code
 * @since 3.0
 */
public class OutboxPublisher {

    private static final Logger logger = LoggerFactory.getLogger(OutboxPublisher.class);

    /** Default timeout for stale claims: 30 seconds. */
    private static final long STALE_CLAIM_TIMEOUT_MS = 30_000;

    private final OutboxStore outboxStore;
    private final HazelcastInstance sharedHazelcast;
    private final OutboxProperties properties;
    private final MeterRegistry meterRegistry;
    private final String memberUuid;

    /**
     * Semaphore used for event-driven wake-up. When a new entry is written to the
     * outbox, {@link #notifyNewEntry()} releases a permit, causing the publisher
     * loop to wake up immediately instead of waiting for the next poll interval.
     */
    private final Semaphore wakeUp = new Semaphore(0);

    private volatile boolean noSharedClusterWarningLogged = false;

    /**
     * Creates a new OutboxPublisher.
     *
     * @param outboxStore the outbox store to poll
     * @param sharedHazelcast the shared Hazelcast instance for ITopic publishing (nullable)
     * @param properties the outbox configuration properties
     * @param meterRegistry the meter registry for metrics
     */
    public OutboxPublisher(final OutboxStore outboxStore,
                           final HazelcastInstance sharedHazelcast,
                           final OutboxProperties properties,
                           final MeterRegistry meterRegistry) {
        this.outboxStore = Objects.requireNonNull(outboxStore, "outboxStore cannot be null");
        this.sharedHazelcast = sharedHazelcast; // nullable — graceful degradation
        this.properties = Objects.requireNonNull(properties, "properties cannot be null");
        this.meterRegistry = Objects.requireNonNull(meterRegistry, "meterRegistry cannot be null");
        this.memberUuid = UUID.randomUUID().toString();
        logger.info("Initialized OutboxPublisher (sharedHazelcast={}, maxBatchSize={}, maxRetries={}, memberUuid={})",
                sharedHazelcast != null ? "connected" : "not configured",
                properties.getMaxBatchSize(), properties.getMaxRetries(), memberUuid);
    }

    /**
     * Signals that a new entry has been written to the outbox, waking up
     * the publisher immediately instead of waiting for the next poll interval.
     *
     * <p>This is safe to call from any thread. Multiple rapid calls are
     * coalesced — the publisher will drain all pending entries in one batch.
     */
    public void notifyNewEntry() {
        // Release at most 1 permit — avoids unbounded permit accumulation
        if (wakeUp.availablePermits() == 0) {
            wakeUp.release();
        }
    }

    /**
     * Waits for either a wake-up signal or the poll interval to elapse,
     * whichever comes first. Called by the scheduling loop between publish cycles.
     *
     * @return true if woken by signal, false if timed out (regular poll)
     */
    public boolean waitForWork() {
        try {
            long timeoutMs = properties.getPollInterval().toMillis();
            return wakeUp.tryAcquire(timeoutMs, java.util.concurrent.TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            return false;
        }
    }

    /**
     * Claims pending outbox entries and delivers them to the shared cluster.
     *
     * <p>Uses atomic claiming ({@link OutboxStore#claimPending}) to prevent
     * duplicate delivery when multiple pods poll the outbox simultaneously.
     * Also sweeps stale claims from members that crashed before delivering.
     *
     * <p>Called by the scheduling loop after {@link #waitForWork()} returns.
     * Also callable directly for immediate delivery.
     */
    public void publishPendingEntries() {
        if (sharedHazelcast == null) {
            if (!noSharedClusterWarningLogged) {
                logger.warn("No shared Hazelcast instance configured — outbox delivery skipped");
                noSharedClusterWarningLogged = true;
            }
            return;
        }

        // Sweep stale claims before claiming new entries
        sweepStaleClaims();

        Timer.Sample sample = Timer.start(meterRegistry);
        try {
            List<OutboxEntry> claimed = outboxStore.claimPending(
                    properties.getMaxBatchSize(), memberUuid);
            if (claimed.isEmpty()) {
                meterRegistry.counter("outbox.poll.empty").increment();
                return;
            }

            int delivered = 0;
            int failed = 0;

            for (OutboxEntry entry : claimed) {
                try {
                    ITopic<GenericRecord> topic = sharedHazelcast.getTopic(entry.getEventType());
                    topic.publish(entry.getEventRecord());
                    outboxStore.markDelivered(entry.getEventId());
                    delivered++;
                    logger.debug("Delivered outbox entry: eventId={}, eventType={}",
                            entry.getEventId(), entry.getEventType());
                } catch (Exception e) {
                    failed++;
                    if (entry.getRetryCount() + 1 >= properties.getMaxRetries()) {
                        outboxStore.markFailed(entry.getEventId(),
                                "Max retries exceeded: " + e.getMessage());
                        meterRegistry.counter("outbox.entries.failed").increment();
                        logger.error("Outbox entry permanently failed after {} retries: eventId={}, reason={}",
                                entry.getRetryCount() + 1, entry.getEventId(), e.getMessage());
                    } else {
                        outboxStore.incrementRetryCount(entry.getEventId(), e.getMessage());
                        logger.warn("Failed to deliver outbox entry (retry {}): eventId={}, reason={}",
                                entry.getRetryCount() + 1, entry.getEventId(), e.getMessage());
                    }
                }
            }

            if (delivered > 0) {
                meterRegistry.counter("outbox.entries.delivered").increment(delivered);
            }

            if (delivered > 0 || failed > 0) {
                logger.info("Outbox publish cycle: delivered={}, failed={}, remaining={}",
                        delivered, failed, claimed.size() - delivered - failed);
            }
        } finally {
            sample.stop(meterRegistry.timer("outbox.publish.duration"));
        }
    }

    /**
     * Releases outbox entries that have been CLAIMED for longer than the stale
     * timeout, reverting them to PENDING so another member can retry.
     *
     * <p>This handles the case where a member claims entries but crashes before
     * delivering them.
     */
    private void sweepStaleClaims() {
        try {
            outboxStore.releaseExpiredClaims(STALE_CLAIM_TIMEOUT_MS);
        } catch (Exception e) {
            logger.warn("Error sweeping stale outbox claims: {}", e.getMessage());
        }
    }
}
